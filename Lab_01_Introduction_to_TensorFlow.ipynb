{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-m1B620PKUGR"
   },
   "source": [
    "**Welcome to Introduction to TensorFlow!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqgiQyKhKZRL"
   },
   "source": [
    "In this lab, we will be understanding how to work with TensorFlow layers and functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pBZjdnrKnNa"
   },
   "source": [
    "We begin with importing the libraries required to continue further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dbYr0PuMY0t"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qkp1YelJLUQ6"
   },
   "source": [
    "Then, we load the data into the memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCYn8nI6Md3R"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64RhiwY-L66v"
   },
   "source": [
    "If we look at the dataframe's properties, we see that there are many columns and rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LhhNS7s9MFt6",
    "outputId": "f5f1a3ed-32da-4070-827d-d38afb269865"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euZBeFE1MK5I"
   },
   "source": [
    "In this example, we will start small. Let's select two columns to proceed with building a model. \n",
    "\n",
    "\n",
    "This leads to building an equation of type:\n",
    "\n",
    "\n",
    "y = f(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7gLK1PjO4Y6"
   },
   "outputs": [],
   "source": [
    "x = data[['radius_mean', 'perimeter_mean']]\n",
    "y = data[['diagnosis']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jf2elZw-Meul"
   },
   "source": [
    "Let's have a look at what we have selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9WmnF3HDO7bl",
    "outputId": "f4e0df12-7a73-466a-95cd-df37888d47ee"
   },
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoDTnK22MlBQ"
   },
   "source": [
    "Always check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QaUS4pBLRkw-",
    "outputId": "2eeb04bb-964c-419f-a39d-f6cc071534b6"
   },
   "outputs": [],
   "source": [
    "print(x.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzXmQRjrMrOn"
   },
   "source": [
    "You can also view the general statistics of your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "S2IO0HQCR0JU",
    "outputId": "c5faec3c-be2a-4451-bc33-0bdd037fdf73"
   },
   "outputs": [],
   "source": [
    "x.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ot-FXnyDMvca"
   },
   "source": [
    "We had a look at our inputs. Now let's have a peek at the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pq2g0uptO9nf",
    "outputId": "f022d239-18d2-4162-efde-043fef8960db"
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iERhaiFM00Z"
   },
   "source": [
    "Normalization brings your dataset into a more managable range. We can apply z-scoring to normalize the dataset. \n",
    "\n",
    "The formula for z-scoring is:\n",
    "\n",
    "normalized_data = (data - mean) / standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OS8e5ZOcO_Yn"
   },
   "outputs": [],
   "source": [
    "# Get the mean and standard deviation\n",
    "stats = x.describe().T\n",
    "mu, sigma = stats['mean'], stats['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "24nRs0FvQ68T",
    "outputId": "b2c595cf-4453-4e83-8215-e481bd17c7d0"
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_norm = (x-mu)/sigma\n",
    "x_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U68S-d-QNUrK"
   },
   "source": [
    "The inputs looks nice and clean now. But our labels are still tricky- they contain values like 'M' and 'B', but tensors work only on numbers. \n",
    "\n",
    "We will now proceed to convert 'M' and 'B' into 1 and 0 so that we can build a classification model distributing the data into 1 and 0. We can then reverse map the predictions to infer 'M' or 'B'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQXNgxyLN3bA"
   },
   "source": [
    "To encode our values from 'M' and 'B' into 1 and 0, we will use lambda functions, and then apply the function logic to every element of our dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Egy7x5llQ9qw"
   },
   "outputs": [],
   "source": [
    "rule = lambda val: 1 if val=='M' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Qbf-d5WRBO0"
   },
   "outputs": [],
   "source": [
    "y=y['diagnosis'].apply(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgwhU5bxOAFM"
   },
   "source": [
    "Let's check out the result of our encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1NZBpteRDY7",
    "outputId": "22022ebb-c20f-48f4-ee14-d2778908ee1c"
   },
   "outputs": [],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1Pqw5t3OJyz"
   },
   "source": [
    "Now that it's all numbers, we can begin designing our first tensorflow network. \n",
    "\n",
    "We begin with defining 'Hyperparameters'. Hyperparameters are values that you can fluctuate to alter model outputs. Parameters are from the dataset- every thing else that you can modify to alter the model results are hyperparamters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Y6kSpUdOdj3"
   },
   "source": [
    "In this example, we have 3 hyperparameters. Epochs tell us how long the model will train for or iterations. Batch size is the number of rows consumed in each step. Learning rate helps us reduce the loss over a period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uppqHYq6RGIS"
   },
   "outputs": [],
   "source": [
    "HP_epochs = 200\n",
    "HP_batch_size = 16\n",
    "HP_lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fp6XRyyJPClz"
   },
   "source": [
    "Then, we divide our dataset into training and scoring datasets. Training dataset will be used to build/train the model, while scoring dataset will be used to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N930jgQARJZJ"
   },
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x_norm,y,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xpj5SLQWPXFe"
   },
   "source": [
    "Now, let's design our model. We are beginning with just 1 layer. This is a fully connected layer, represented as 'Dense' in TensorFlow. Using only one layer gives us the following model equation:\n",
    "\n",
    "\n",
    "y = weight1 * x1 + weight2 * x2 + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0Jj4oYNSXYs"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6WHomkwPt18"
   },
   "source": [
    "The next step is to compile the model. Compiling specifies how the loss will be calculated, and optimized to yield a hopefully lower loss. This is where we use learning rate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjhTV9qvS3TE"
   },
   "outputs": [],
   "source": [
    "my_optimizer = tf.keras.optimizers.Adam(learning_rate=HP_lr)\n",
    "my_error = 'mean_absolute_error'\n",
    "model.compile(\n",
    "    optimizer=my_optimizer,\n",
    "    loss=my_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRBtBE1zQIyr"
   },
   "source": [
    "Notice how we could just use 'mean_absolute_error' as a string! TensorFlow allows us to use many such strings as predefined deep learning entities! Loss functions, optimization functions and metrics are such examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G52Zcd2QQY0t"
   },
   "outputs": [],
   "source": [
    "# Do Not Uncomment- this is an alternate example\n",
    "# FOR READING ONLY\n",
    "# Note: instead of our own optimizer, \n",
    "# we could have also defined our optimizer as\n",
    "# my_optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gsx6NTY7Qpdf"
   },
   "source": [
    "Now, we will train the model. Training is the process of fitting a curve/algebric equation through the dataset. This equation is then used to predict future inputs.\n",
    "\n",
    "We are using the EPOCH hyperparameter here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mw3K-25PS_tR",
    "outputId": "6230b26b-7955-4799-d958-32412aa247e0"
   },
   "outputs": [],
   "source": [
    "model.fit(xtrain, ytrain, epochs=HP_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gah2ruhqREGX"
   },
   "source": [
    "Let's have a look at the model we designed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OhNJdwYgVkjy",
    "outputId": "b3201ff6-001c-4add-96b6-dab2a6a299c5"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5TT9OqcRILR"
   },
   "source": [
    "The trainable parameters can be calculated in the following manner:\n",
    "\n",
    "We have two types of trainable parameters in this example- weights and bias. \n",
    "\n",
    "Weights are calculated for each input and output. <br/> \n",
    "\n",
    "Hence, total weights = inputs * output\n",
    "\n",
    "Bias is calculated for each output. Total bias = output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6ZTkqOpRpXz"
   },
   "source": [
    "Here, we have 2 inputs (x1 and x2), and 1 output (y).\n",
    "\n",
    "\n",
    "Total parameters = weights + bias\n",
    "\n",
    "Total parameters = input * output + output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCEdWHoJR1LJ"
   },
   "source": [
    "In our case, this happens to be\n",
    "\n",
    "Total parameters = 2 * 1 + 1\n",
    "\n",
    "= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ko3IC_DPSEZp"
   },
   "source": [
    "<br/>\n",
    "Now let's get some predictions from our model, and have a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7fUgmLYTZe1",
    "outputId": "c3724b9a-7648-4bc1-cd9d-33b7e98183a6"
   },
   "outputs": [],
   "source": [
    "train_predictions = model.predict(xtrain)\n",
    "test_predictions = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9k3ORWjATwZw",
    "outputId": "d87d2960-1129-45e5-c457-13f632a71036"
   },
   "outputs": [],
   "source": [
    "train_predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rwf1Rx36SWWz"
   },
   "source": [
    "The model outputs don't look like 1 and 0- they are values calculated with the help of our trained model\n",
    "<br/><br/>\n",
    "y = weight1*x1 + weight2*x2 + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_731l99lSmit"
   },
   "source": [
    "We will convert them now into 1 and 0, for the ease of calculation, and the ease of decoding to 'M' and 'B'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COjTacl-TyFJ"
   },
   "outputs": [],
   "source": [
    "rule = lambda val: 1 if val>=0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8qLZjC8T4Tf"
   },
   "outputs": [],
   "source": [
    "train_predictions = [ rule(prediction) for prediction in train_predictions]\n",
    "test_predictions = [ rule(prediction) for prediction in test_predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hfbCq2USy8W"
   },
   "source": [
    "Let's have a look at the transformed labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "huG1HavlT6zm",
    "outputId": "2b70284c-8fa0-42fe-e52e-d868e2c5b6ef"
   },
   "outputs": [],
   "source": [
    "test_predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTOiRtIGS5ER"
   },
   "source": [
    "Now let's check how well our model performed. <br/><br/>\n",
    "Accuracy is an easy equation- out of all guesses, how many did our model get right? A 100% accuracy is represented by 1, and 0% accuracy as 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xReFh27JTk8h"
   },
   "source": [
    "How did our model perform on the dataset that it was trained on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db4hy14rUDdz",
    "outputId": "81c25eb8-d568-40d5-9e4f-7740000feb30"
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(train_predictions,ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJbxhhRwTSgE",
    "outputId": "1a18dc79-2792-4b62-d712-be589be64da1"
   },
   "outputs": [],
   "source": [
    "# or in %\n",
    "print(str(accuracy_score(train_predictions,ytrain)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4wiKTKrTs0q"
   },
   "source": [
    "How did our model perform on unknown data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TydCZwmRUu9R",
    "outputId": "7dff82f6-6199-47d7-946f-95791efd7c89"
   },
   "outputs": [],
   "source": [
    "accuracy_score(test_predictions,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAko1oUDTxI7"
   },
   "source": [
    "Are the values close enough? Are they too far away from each other? Is this overfitting? Is this underfitting? We will answer these questions slowly over the next few labs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqYk9aYtT_BM"
   },
   "source": [
    "To use this model elsewhere, simply save it. One of the ways to save it is using 'save' function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vq_dR3N8VQVH"
   },
   "outputs": [],
   "source": [
    "model.save('first_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeFFDRxAUGbI"
   },
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kATBcLAUIWe"
   },
   "source": [
    "In this lab, we learnt the following:\n",
    "\n",
    "\n",
    "\n",
    "*   Read the data and clean it\n",
    "*   Break the data into inputs and labels\n",
    "*   Normalize the inputs and encode the labels if required\n",
    "*   Distribute the data into training and scoring datasets\n",
    "*   Design the neural network and compile it\n",
    "*   Train the model with training dataset\n",
    "*   Test the model with scoring dataset\n",
    "*   Use metrics (such as accuracy) to validate the dataset\n",
    "<br/><br/>\n",
    "Save the model if required!\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
