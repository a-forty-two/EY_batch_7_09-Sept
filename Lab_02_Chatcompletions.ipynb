{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu36fbruGQ6f",
        "outputId": "aaf385f7-5d4e-4987-c7ef-a4eebde4d071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.13.3\n",
            "  Downloading openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.13.3) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.13.3)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.13.3) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.13.3) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.13.3) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.13.3)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.13.3)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.13.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.13.3) (2.20.1)\n",
            "Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 openai-1.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.13.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1712333180112
        },
        "id": "TzNu4LTKGQ6h"
      },
      "outputs": [],
      "source": [
        "# Add Azure OpenAI package\n",
        "from openai import AzureOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1712333182445
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "JleYn8CgGQ6h"
      },
      "outputs": [],
      "source": [
        "azure_oai_endpoint =\"openAI endpoint\"\n",
        "azure_oai_key =\"your open AI instance key\"\n",
        "azure_oai_deployment =\"your gpt deployment name\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qazJ6DMyMHeP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1712333183879
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "8b0vbI7OGQ6h"
      },
      "outputs": [],
      "source": [
        "# Initialize the Azure OpenAI client\n",
        "client = AzureOpenAI(\n",
        "        azure_endpoint = azure_oai_endpoint,\n",
        "        api_key=azure_oai_key,\n",
        "        api_version=\"2024-02-15-preview\"\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1712333189626
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8BsE9a_GQ6h",
        "outputId": "9f77b737-d78d-446d-f267-7e43b30ec62b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-A6AJoGxbe0UmQLUlZy0W8RolvB66S', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Oh, absolutely! Polar bears are big fans of pizzas. In fact, they have been known to have pizza parties in the Arctic. They even have their own special toppings like seal sausage and fish fillets.', role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1726032996, model='gpt-35-turbo-16k', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=42, prompt_tokens=60, total_tokens=102), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
          ]
        }
      ],
      "source": [
        "# Add code to send request...\n",
        "# Send request to Azure OpenAI model\n",
        "response = client.chat.completions.create(\n",
        "    model=azure_oai_deployment,\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant with a lot of humor.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do penguins like pizzas?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Yes, penguins like pizza very much. They also like chips and hummus.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do polar bears support pizzas too?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1712333189871
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXTSDZIpGQ6i",
        "outputId": "f5d803ba-8485-4620-d927-68af2ee8ca11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Oh, absolutely! Polar bears are big fans of pizzas as well. In fact, they have been known to have pizza parties in the Arctic Circle. Just be careful not to get too close to their pizza, they can get a bit territorial when it comes to their favorite toppings!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "generated_text = response.choices[0].message.content\n",
        "\n",
        "# Print the response\n",
        "print(\"Response: \" + generated_text + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "z7aT9ASTGQ6i"
      },
      "source": [
        "**Maintain Chat History**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1712333260307
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "rXFT6hdrGQ6j"
      },
      "outputs": [],
      "source": [
        "# To maintain chat hisotry, we initialize messages array and append all interactions to the messages array\n",
        "messages_array = [ {\"role\": \"system\", \"content\": \"You are a helpful assistant with a lot of humor.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do penguins like pizzas?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Yes, penguins like pizza very much. They also like chips and hummus.\"}\n",
        "\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1712333261573
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "rrPw7hrxGQ6j"
      },
      "outputs": [],
      "source": [
        "input_text = \"what kind of potatoes do bears like?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1712333265598
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt586ANEGQ6k",
        "outputId": "642910e9-81d9-4770-aeae-841687e62a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Bears have quite a refined taste when it comes to potatoes. They prefer \"bearrusset\" potatoes, which are specially grown for their bear-sized\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Add code to send request...\n",
        "# Send request to Azure OpenAI model\n",
        "messages_array.append({\"role\": \"user\", \"content\": input_text})\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=azure_oai_deployment,\n",
        "    temperature=0.7,\n",
        "    max_tokens=30,\n",
        "    messages=messages_array\n",
        ")\n",
        "generated_text = response.choices[0].message.content\n",
        "# Add generated text to messages array\n",
        "messages_array.append({\"role\": \"system\", \"content\": generated_text})\n",
        "\n",
        "# Print generated text\n",
        "print(\"Summary: \" + generated_text + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "-NwvG9vYGQ6k"
      },
      "source": [
        "**Let's check out the messages array**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1712333314293
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e92Zz2sPGQ6k",
        "outputId": "811e8654-4456-409d-8873-78e5b01f2e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': 'You are a helpful assistant with a lot of humor.'}, {'role': 'user', 'content': 'Do penguins like pizzas?'}, {'role': 'assistant', 'content': 'Yes, penguins like pizza very much. They also like chips and hummus.'}, {'role': 'user', 'content': 'what kind of potatoes do bears like?'}, {'role': 'system', 'content': 'Bears have quite a refined taste when it comes to potatoes. They prefer \"bearrusset\" potatoes, which are specially grown for their bear-sized'}]\n"
          ]
        }
      ],
      "source": [
        "print(messages_array)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qhbQzKUqH86C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}